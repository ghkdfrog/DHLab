{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99912968-2039-4e39-a90f-6e9ce2812d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchOptics.optics as tt\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torchOptics.metrics as tm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torchvision\n",
    "import datetime\n",
    "import tqdm\n",
    "import time\n",
    "import HHS.model\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class SignFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        t = torch.Tensor([0.5]).cuda()  # threshold\n",
    "        output = (input > t).float() * 1\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output * torch.ones_like(input)  # Replace with your custom gradient computation\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class Dataset512(Dataset):\n",
    "    def __init__(self, target_dir, meta, transform=None, isTrain=True):\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.meta = meta\n",
    "        self.isTrain = isTrain\n",
    "        self.target_list = sorted(glob.glob(target_dir+'*.png'))\n",
    "        self.center_crop = torchvision.transforms.CenterCrop(512)\n",
    "        self.random_crop = torchvision.transforms.RandomCrop((512, 512))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        target = tt.imread(self.target_list[idx], meta=meta)\n",
    "        if self.isTrain:\n",
    "            target = self.random_crop(target)\n",
    "        else:\n",
    "            target = self.center_crop(target)\n",
    "        return target\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# load data\n",
    "batch_size = 1\n",
    "target_dir = 'dataset/DIV2K/DIV2K_train_HR/'\n",
    "valid_dir = 'dataset/DIV2K/DIV2K_valid_HR/'\n",
    "# sim_dir = 'binary_dataset/simulated/'\n",
    "meta = {'wl' : (638e-9, 515e-9, 450e-9), 'dx':(6.3e-6, 6.3e-6)}\n",
    "train_dataset = Dataset512(target_dir=target_dir, meta=meta, isTrain=True)\n",
    "valid_dataset = Dataset512(target_dir=valid_dir, meta=meta, isTrain=False)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "validloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def train(model, num_hologram=10, custom_name='fcn', epochs=100, lr=1e-4, z=2e-3):\n",
    "    date = datetime.datetime.now() - datetime.timedelta(hours=15)\n",
    "    mean_psnr_list = []\n",
    "    mean_mse_list = []\n",
    "    max_epoch = 0\n",
    "    max_psnr = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sign_function = SignFunction.apply\n",
    "    # path = 'models/'\n",
    "    model_name = f'{date}_{custom_name}_{num_hologram}_{z}'\n",
    "    # make result folder\n",
    "    result_folder = 'result/'+model_name\n",
    "    os.mkdir(result_folder)\n",
    "    model_path = os.path.join(result_folder, model_name)\n",
    "    psnr_result_path = os.path.join(result_folder, 'meanPSNR.npy')\n",
    "    mse_result_path = os.path.join(result_folder, 'meanMSE.npy')\n",
    "    result = {'model_path': model_path, 'psnr_result_path': psnr_result_path,\n",
    "          'mse_result_path': mse_result_path, 'z': z,\n",
    "          'num_hologram': num_hologram, 'lr': lr, 'epochs': epochs}\n",
    "    # save result dict\n",
    "    with open(os.path.join(result_folder, 'result_dict.pickle'), 'wb') as fw:\n",
    "        pickle.dump(result, fw)\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm.tqdm(trainloader)\n",
    "        model.train()\n",
    "        for target in pbar:\n",
    "            out = model(target)\n",
    "            binary = sign_function(out)\n",
    "            sim = tt.simulate(binary, z).abs()**2\n",
    "            result = torch.mean(sim, dim=1, keepdim=True)\n",
    "            loss = tt.relativeLoss(result, target, F.mse_loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            psnrList = []\n",
    "            mseList = []\n",
    "            for valid in validloader:\n",
    "                out = model(valid)\n",
    "                binary = sign_function(out)\n",
    "                sim = tt.simulate(binary, z).abs()**2\n",
    "                result = torch.mean(sim, dim=1, keepdim=True)\n",
    "                psnr = tt.relativeLoss(result, valid, tm.get_PSNR)\n",
    "                psnrList.append(psnr)\n",
    "                mse = tt.relativeLoss(result, valid, F.mse_loss).detach().cpu().numpy()\n",
    "                mseList.append(mse)\n",
    "            mean_psnr = sum(psnrList)/len(psnrList)\n",
    "            mean_mse = sum(mseList)/len(mseList)\n",
    "            mean_psnr_list.append(mean_psnr)\n",
    "            mean_mse_list.append(mean_mse)\n",
    "            # save psnr and mse\n",
    "            np.save(psnr_result_path, mean_psnr_list)\n",
    "            np.save(mse_result_path, mean_mse_list)\n",
    "            plt.plot(np.arange(len(mean_psnr_list)), mean_psnr_list,\n",
    "                     label=f'max psnr: {max(mean_psnr_list)}')\n",
    "            plt.title(model_name+'_psnr')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanPSNR.png'))\n",
    "            plt.clf()\n",
    "            plt.plot(np.arange(len(mean_mse_list)), mean_mse_list,\n",
    "                     label=f'max psnr: {min(mean_mse_list)}')\n",
    "            plt.title(model_name+'_mse')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanMSE.png'))\n",
    "            plt.clf()\n",
    "            print(f'mean PSNR : {mean_psnr} {epoch}/{epochs}')\n",
    "            print(f'mean MSE : {mean_mse} {epoch}/{epochs}')\n",
    "\n",
    "        if mean_psnr > max_psnr:\n",
    "            max_psnr = mean_psnr\n",
    "            max_epoch = epoch\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(f'max_psnr: {max_psnr}, epoch: {max_epoch}')\n",
    "\n",
    "\n",
    "def binary_sim(out, z=2e-3):\n",
    "    binary = SignFunction.apply(out)\n",
    "    sim = tt.simulate(binary, z).abs()**2\n",
    "    res = torch.mean(sim, dim=1, keepdim=True)\n",
    "    return binary, res\n",
    "\n",
    "\n",
    "def valid(model):\n",
    "    with torch.no_grad():\n",
    "        psnr_list = []\n",
    "        for target in validloader:\n",
    "            out = model(target)\n",
    "            binary, res = binary_sim(out)\n",
    "            psnr = tt.relativeLoss(res, target, tm.get_PSNR)\n",
    "            psnr_list.append(psnr)\n",
    "    print(sum(psnr_list)/len(psnr_list))\n",
    "\n",
    "\n",
    "def check_order(bmodel, classifier, target):\n",
    "    if len(target.shape) == 3:\n",
    "        target = target.unsqueeze(0)\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        out = bmodel(target)\n",
    "        binary, res = binary_sim(out)\n",
    "        for i in range(10):\n",
    "            binary_input = binary[0][i].unsqueeze(0).unsqueeze(0)\n",
    "            prop_order = classifier(binary_input)\n",
    "            result.append(torch.argmax(prop_order))\n",
    "    print(result)\n",
    "\n",
    "\n",
    "def check_order_without_model(binary, classifier):\n",
    "    with torch.no_grad():\n",
    "        result = []\n",
    "        for i in range(10):\n",
    "            binary_input = binary[0][i].unsqueeze(0).unsqueeze(0)\n",
    "            prop_order = classifier(binary_input)\n",
    "            result.append(torch.argmax(prop_order))\n",
    "    print(result)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc = nn.Linear(64 * 64 * 64, 10)  # 최종 분류를 위한 FC 레이어\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 64 * 64)  # flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def rgb_binary_sim(out, z):\n",
    "    meta = {'wl' : (638e-9, 515e-9, 450e-9), 'dx':(6.3e-6, 6.3e-6)}\n",
    "    rmeta = {'wl': (638e-9), 'dx': (6.3e-6, 6.3e-6)}\n",
    "    gmeta = {'wl': (515e-9), 'dx': (6.3e-6, 6.3e-6)}\n",
    "    bmeta = {'wl': (450e-9), 'dx': (6.3e-6, 6.3e-6)}\n",
    "    sign = SignFunction.apply\n",
    "    binary = sign(out)\n",
    "    channel = out.shape[1]\n",
    "    rchannel = int(channel/3)\n",
    "    gchannel = int(channel*2/3)\n",
    "    red = binary[:, :rchannel, :, :]\n",
    "    green = binary[:, rchannel:gchannel, :, :]\n",
    "    blue = binary[:, gchannel:, :, :]\n",
    "    red = tt.Tensor(red, meta=rmeta)\n",
    "    green = tt.Tensor(green, meta=gmeta)\n",
    "    blue = tt.Tensor(blue, meta=bmeta)\n",
    "    rsim = tt.simulate(red, z).abs()**2\n",
    "    gsim = tt.simulate(green, z).abs()**2\n",
    "    bsim = tt.simulate(blue, z).abs()**2\n",
    "    rmean = torch.mean(rsim, dim=1, keepdim=True)\n",
    "    gmean = torch.mean(gsim, dim=1, keepdim=True)\n",
    "    bmean = torch.mean(bsim, dim=1, keepdim=True)\n",
    "    rgb = torch.cat([rmean, gmean, bmean], dim=1)\n",
    "    rgb = tt.Tensor(rgb, meta=meta)\n",
    "    binary = tt.Tensor(binary, meta=meta)\n",
    "    return binary, rgb\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eb3f555-4a6f-455a-b10e-fbcbce28b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_binary_train_padding(model, num_hologram=10, custom_name='fcn', epochs=100, lr=1e-4, z=2e-3, dataset='DIV2K'):\n",
    "    date = datetime.datetime.now() - datetime.timedelta(hours=15)\n",
    "    channels = []\n",
    "    model.apply(initialize_weights)\n",
    "    mean_psnr_list = []\n",
    "    mean_mse_list = []\n",
    "    max_epoch = 0\n",
    "    max_psnr = 0\n",
    "    crop = torchvision.transforms.CenterCrop(480)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sign_function = SignFunction.apply\n",
    "    # path = 'models/'\n",
    "    model_name = f'{date}_{custom_name}_{num_hologram}_{z}'\n",
    "    # make result folder\n",
    "    result_folder = 'result/layer6'+model_name\n",
    "    os.mkdir(result_folder)\n",
    "    num_parameters = count_parameters(model)\n",
    "    model_path = os.path.join(result_folder, 'best')\n",
    "    final_psth = os.path.join(result_folder, 'final')\n",
    "    psnr_result_path = os.path.join(result_folder, 'meanPSNR.npy')\n",
    "    mse_result_path = os.path.join(result_folder, 'meanMSE.npy')\n",
    "    result = {'model_path': model_path, 'psnr_result_path': psnr_result_path,\n",
    "          'mse_result_path': mse_result_path, 'z': z,\n",
    "          'num_hologram': num_hologram, 'lr': lr, 'epochs': epochs,\n",
    "            'num_parameters': num_parameters, 'channels': channels,\n",
    "             'dataset': dataset}\n",
    "    # save result dict\n",
    "    train_psnr_list = []\n",
    "    train_loss_list = []\n",
    "    with open(os.path.join(result_folder, 'result_dict.pickle'), 'wb') as fw:\n",
    "        pickle.dump(result, fw)\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm.tqdm(trainloader)\n",
    "        model.train()\n",
    "        sum_train_psnr = 0\n",
    "        sum_train_loss = 0\n",
    "        for target in pbar:\n",
    "            out = model(target)\n",
    "            out = torch.nn.Sigmoid()(out)\n",
    "            binary, rgb = rgb_binary_sim(out, z)\n",
    "            rgb = crop(rgb)\n",
    "            croped_target = crop(target)\n",
    "            loss = tt.relativeLoss(rgb, croped_target, F.mse_loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            psnr = tt.relativeLoss(rgb, croped_target, tm.get_PSNR)\n",
    "            sum_train_psnr = sum_train_psnr + psnr\n",
    "            sum_train_loss = sum_train_loss + loss.detach().cpu().numpy()\n",
    "        mean_train_psnr = sum_train_psnr/len(trainloader)\n",
    "        mean_train_loss = sum_train_loss/len(trainloader)\n",
    "        train_psnr_list.append(mean_train_psnr)\n",
    "        train_loss_list.append(mean_train_loss)\n",
    "\n",
    "        plt.plot(np.arange(len(train_psnr_list)), train_psnr_list, label=f'max psnr: {max(train_psnr_list)}')\n",
    "        plt.title(model_name+'_train_psnr')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(result_folder, 'trainPSNR.png'))\n",
    "        plt.clf()\n",
    "        \n",
    "        plt.plot(np.arange(len(train_loss_list)), train_loss_list, label=f'min mse: {min(train_loss_list)}')\n",
    "        plt.title(model_name+'_train_loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(result_folder, 'trainMSE.png'))\n",
    "        plt.clf()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            psnrList = []\n",
    "            mseList = []\n",
    "            for idx, valid in enumerate(validloader):\n",
    "                out = model(valid)\n",
    "                # out = torch.nn.Sigmoid()(out)\n",
    "                binary, rgb = rgb_binary_sim(out, z)\n",
    "                rgb = crop(rgb)\n",
    "                croped_target = crop(valid)\n",
    "                psnr = tt.relativeLoss(rgb, croped_target, tm.get_PSNR)\n",
    "                psnrList.append(psnr)\n",
    "                mse = tt.relativeLoss(rgb, croped_target, F.mse_loss).detach().cpu().numpy()\n",
    "                mseList.append(mse)\n",
    "                if idx == 0:\n",
    "                    pl = tt.show_with_insets(rgb, croped_target, correct_colorwise=True)\n",
    "                    pl.save(os.path.join(result_folder, 'penguin.png'))\n",
    "            mean_psnr = sum(psnrList)/len(psnrList)\n",
    "            mean_mse = sum(mseList)/len(mseList)\n",
    "            mean_psnr_list.append(mean_psnr)\n",
    "            mean_mse_list.append(mean_mse)\n",
    "            # save psnr and mse\n",
    "            np.save(psnr_result_path, mean_psnr_list)\n",
    "            np.save(mse_result_path, mean_mse_list)\n",
    "            plt.plot(np.arange(len(mean_psnr_list)), mean_psnr_list,\n",
    "                     label=f'max psnr: {max(mean_psnr_list)}')\n",
    "            plt.title(model_name+'_psnr')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanPSNR.png'))\n",
    "            plt.clf()\n",
    "            plt.plot(np.arange(len(mean_mse_list)), mean_mse_list,\n",
    "                     label=f'min mse: {min(mean_mse_list)}')\n",
    "            plt.title(model_name+'_mse')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(result_folder, 'meanMSE.png'))\n",
    "            plt.clf()\n",
    "            print(f'mean PSNR : {mean_psnr} {epoch}/{epochs}')\n",
    "            print(f'mean MSE : {mean_mse} {epoch}/{epochs}')\n",
    "\n",
    "        if mean_psnr > max_psnr:\n",
    "            max_psnr = mean_psnr\n",
    "            max_epoch = epoch\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        torch.save(model.state_dict(), final_psth)\n",
    "        print(f'max_psnr: {max_psnr}, epoch: {max_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f97d1545-27ce-4e94-9e74-db2d914bcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_num = 24\n",
    "model = tt.Net(in_channels=[3]+[32 for _ in range(20)]+[binary_num], activations='LeakyReLU').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51564677-d241-40d9-9f00-b6e84d7f71a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "target = train_dataset[0].unsqueeze(0)\n",
    "out = model(target)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27bcb3-c387-49f1-9890-70f1cb277c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [01:51<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean PSNR : 11.666082890033723 0/500\n",
      "mean MSE : 0.07282490679994226 0/500\n",
      "max_psnr: 11.666082890033723, epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [01:51<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean PSNR : 11.978643922805785 1/500\n",
      "mean MSE : 0.0737042583990842 1/500\n",
      "max_psnr: 11.978643922805785, epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [01:51<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean PSNR : 11.417895178794861 2/500\n",
      "mean MSE : 0.08642679915763438 2/500\n",
      "max_psnr: 11.978643922805785, epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [01:51<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean PSNR : 12.574602155685424 3/500\n",
      "mean MSE : 0.0602491367328912 3/500\n",
      "max_psnr: 12.574602155685424, epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 510/800 [01:11<00:41,  6.98it/s]"
     ]
    }
   ],
   "source": [
    "rgb_binary_train_padding(model, num_hologram=24, custom_name='tt net', epochs=500, lr=1e-4, z=2e-3, dataset='DIV2K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68d85a-b24f-402c-86a6-e1f552ba3617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
